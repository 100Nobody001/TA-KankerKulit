{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d0591a",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040aa83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Z6\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import itertools\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4ab6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7799f",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b603ac4",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08441d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = r\"C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Skripsi dataset\\Undersampling Training 4515 (NV 6705-5500=1205)\\Pembagian Berdasarkan Kanker atau Tidak\\Training Data\"\n",
    "CATEGORIES = [\"Kanker\", \"Non-Kanker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49fa850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1954/1954 [00:41<00:00, 47.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2561/2561 [00:55<00:00, 45.84it/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to class\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0,1,2,etc)\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per class\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f7de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4515\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbaf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle training data\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe33169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning into matrix for feature and label\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e129b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4515, 64, 64, 3)\n",
      "(4515,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e93ff4",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9df1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR_TEST = r\"C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Skripsi dataset\\Undersampling Training 4515 (NV 6705-5500=1205)\\Pembagian Berdasarkan Kanker atau Tidak\\Test Data\"\n",
    "CATEGORIES = [\"Kanker\", \"Non-Kanker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb62c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 307/307 [00:06<00:00, 45.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1205/1205 [00:25<00:00, 46.75it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "\n",
    "\n",
    "def create_test_data():\n",
    "    for category in CATEGORIES:\n",
    "\n",
    "        path = os.path.join(DATADIR_TEST,category)  # create path to class\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0,1,2,etc)\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per class\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                test_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32d33ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21832fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turning into matrix for feature and label\n",
    "X_Test= []\n",
    "y_Test = []\n",
    "\n",
    "for features,label in test_data:\n",
    "    X_Test.append(features)\n",
    "    y_Test.append(label)\n",
    "\n",
    "\n",
    "X_Test= np.array(X_Test).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y_Test = np.array(y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5692aa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1512, 64, 64, 3)\n",
      "(1512,)\n"
     ]
    }
   ],
   "source": [
    "print(X_Test.shape)\n",
    "print(y_Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8518b6",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42b27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "path = r'C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Skripsi dataset\\Undersampling Training 4515 (NV 6705-5500=1205)\\Pembagian Berdasarkan Kanker atau Tidak\\\\'\n",
    "pickle_out = open(path + \"X.pickle.64\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(path + \"y.pickle.64\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b566f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "path = r'C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Skripsi dataset\\Undersampling Training 4515 (NV 6705-5500=1205)\\Pembagian Berdasarkan Kanker atau Tidak\\\\'\n",
    "pickle_out = open(path + \"X.pickle.64.Test\",\"wb\")\n",
    "pickle.dump(X_Test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(path + \"y.pickle.64.Test\",\"wb\")\n",
    "pickle.dump(y_Test, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5a6a2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0194f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data\n",
    "path = r'C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Skripsi dataset\\Undersampling Training 4515 (NV 6705-5500=1205)\\Pembagian Berdasarkan Kanker atau Tidak\\\\'\n",
    "pickle_in = open(path + \"X.pickle.224\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(path + \"y.pickle.224\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe0e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "path = r'C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Skripsi dataset\\Undersampling Training 4515 (NV 6705-5500=1205)\\Pembagian Berdasarkan Kanker atau Tidak\\\\'\n",
    "pickle_in = open(path + \"X.pickle.224.Test\",\"rb\")\n",
    "X_Test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(path + \"y.pickle.224.Test\",\"rb\")\n",
    "y_Test = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d112f",
   "metadata": {},
   "source": [
    "# Build CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e717ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Data\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5da4fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = to_categorical(y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1dffdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Deteksi Kanker Berdasarkan Penyakit-CNN-{}\".format(int(time.time()))\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation=LeakyReLU(alpha=0.01), padding = 'same', strides = 2, input_shape=(X.shape[1:])),\n",
    "    AveragePooling2D(pool_size=(3, 3), strides=2),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation=LeakyReLU(alpha=0.01), padding = 'same', strides = 2, input_shape=(X.shape[1:])),\n",
    "    AveragePooling2D(pool_size=(3, 3), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=64, activation=LeakyReLU(alpha=0.01)),\n",
    "    Dense(units=128, activation=LeakyReLU(alpha=0.01)),\n",
    "    Dense(units=256, activation=LeakyReLU(alpha=0.01)),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ea27cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 112, 112, 64)      1792      \n",
      "                                                                 \n",
      " average_pooling2d_24 (Aver  (None, 55, 55, 64)        0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " average_pooling2d_25 (Aver  (None, 13, 13, 128)       0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 64)                1384512   \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1502018 (5.73 MB)\n",
      "Trainable params: 1502018 (5.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69e1a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelCheckpoint callback saves a model at some interval. \n",
    "filepath=r\"C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-{epoch:02d}-{val_recall:.2f}.hdf5\" #File name includes epoch and validation accuracy.\n",
    "#Use Mode = max for accuracy and min for loss. \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_recall', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_recall', patience=10, verbose=1, mode='max')\n",
    "\n",
    "#CSVLogger logs epoch, acc, loss, val_acc, val_loss\n",
    "log_csv = CSVLogger('Model sendiri 6.csv', separator=',', append=False)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stop, log_csv]\n",
    "#callbacks_list = [checkpoint, log_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f35685ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6684 - recall: 0.5462\n",
      "Epoch 1: val_recall improved from -inf to 0.42525, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-01-0.43.hdf5\n",
      "113/113 [==============================] - 17s 137ms/step - loss: 0.6684 - recall: 0.5462 - val_loss: 0.6977 - val_recall: 0.4252\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6711 - recall: 0.5545\n",
      "Epoch 2: val_recall improved from 0.42525 to 0.58583, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-02-0.59.hdf5\n",
      "113/113 [==============================] - 15s 129ms/step - loss: 0.6711 - recall: 0.5545 - val_loss: 0.6435 - val_recall: 0.5858\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6396 - recall: 0.5786\n",
      "Epoch 3: val_recall improved from 0.58583 to 0.60465, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-03-0.60.hdf5\n",
      "113/113 [==============================] - 15s 128ms/step - loss: 0.6396 - recall: 0.5786 - val_loss: 0.6505 - val_recall: 0.6047\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6218 - recall: 0.5914\n",
      "Epoch 4: val_recall improved from 0.60465 to 0.61794, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-04-0.62.hdf5\n",
      "113/113 [==============================] - 15s 129ms/step - loss: 0.6218 - recall: 0.5914 - val_loss: 0.5951 - val_recall: 0.6179\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6103 - recall: 0.6091\n",
      "Epoch 5: val_recall did not improve from 0.61794\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.6103 - recall: 0.6091 - val_loss: 0.6404 - val_recall: 0.5692\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6280 - recall: 0.5941\n",
      "Epoch 6: val_recall did not improve from 0.61794\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.6280 - recall: 0.5941 - val_loss: 0.5926 - val_recall: 0.6168\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.6004 - recall: 0.6431\n",
      "Epoch 7: val_recall improved from 0.61794 to 0.62126, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-07-0.62.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.6004 - recall: 0.6431 - val_loss: 0.5894 - val_recall: 0.6213\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5985 - recall: 0.6346\n",
      "Epoch 8: val_recall did not improve from 0.62126\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5985 - recall: 0.6346 - val_loss: 0.5954 - val_recall: 0.6157\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5766 - recall: 0.6620\n",
      "Epoch 9: val_recall improved from 0.62126 to 0.65116, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-09-0.65.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5766 - recall: 0.6620 - val_loss: 0.5834 - val_recall: 0.6512\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5624 - recall: 0.6830\n",
      "Epoch 10: val_recall improved from 0.65116 to 0.65781, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-10-0.66.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5624 - recall: 0.6830 - val_loss: 0.5678 - val_recall: 0.6578\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5660 - recall: 0.6830\n",
      "Epoch 11: val_recall did not improve from 0.65781\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5660 - recall: 0.6830 - val_loss: 0.6323 - val_recall: 0.5825\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5823 - recall: 0.6614\n",
      "Epoch 12: val_recall improved from 0.65781 to 0.67553, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-12-0.68.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5823 - recall: 0.6614 - val_loss: 0.5805 - val_recall: 0.6755\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5455 - recall: 0.7029\n",
      "Epoch 13: val_recall did not improve from 0.67553\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5455 - recall: 0.7029 - val_loss: 0.5684 - val_recall: 0.6578\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5380 - recall: 0.7046\n",
      "Epoch 14: val_recall improved from 0.67553 to 0.68660, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-14-0.69.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5380 - recall: 0.7046 - val_loss: 0.5564 - val_recall: 0.6866\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5271 - recall: 0.7101\n",
      "Epoch 15: val_recall did not improve from 0.68660\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5271 - recall: 0.7101 - val_loss: 0.5853 - val_recall: 0.6667\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5380 - recall: 0.7104\n",
      "Epoch 16: val_recall did not improve from 0.68660\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5380 - recall: 0.7104 - val_loss: 0.5869 - val_recall: 0.6822\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5175 - recall: 0.7243\n",
      "Epoch 17: val_recall did not improve from 0.68660\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5175 - recall: 0.7243 - val_loss: 0.5966 - val_recall: 0.6722\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5117 - recall: 0.7226\n",
      "Epoch 18: val_recall did not improve from 0.68660\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5117 - recall: 0.7226 - val_loss: 0.5826 - val_recall: 0.6766\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5085 - recall: 0.7284\n",
      "Epoch 19: val_recall did not improve from 0.68660\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.5085 - recall: 0.7284 - val_loss: 0.6012 - val_recall: 0.6578\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.5035 - recall: 0.7339\n",
      "Epoch 20: val_recall improved from 0.68660 to 0.69989, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-20-0.70.hdf5\n",
      "113/113 [==============================] - 15s 129ms/step - loss: 0.5035 - recall: 0.7339 - val_loss: 0.5601 - val_recall: 0.6999\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4906 - recall: 0.7328\n",
      "Epoch 21: val_recall did not improve from 0.69989\n",
      "113/113 [==============================] - 15s 129ms/step - loss: 0.4906 - recall: 0.7328 - val_loss: 0.5848 - val_recall: 0.6788\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4809 - recall: 0.7445\n",
      "Epoch 22: val_recall did not improve from 0.69989\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.4809 - recall: 0.7445 - val_loss: 0.5778 - val_recall: 0.6800\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4708 - recall: 0.7589\n",
      "Epoch 23: val_recall improved from 0.69989 to 0.70210, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-23-0.70.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 15s 129ms/step - loss: 0.4708 - recall: 0.7589 - val_loss: 0.5553 - val_recall: 0.7021\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4610 - recall: 0.7674\n",
      "Epoch 24: val_recall did not improve from 0.70210\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.4610 - recall: 0.7674 - val_loss: 0.5916 - val_recall: 0.6977\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4465 - recall: 0.7727\n",
      "Epoch 25: val_recall improved from 0.70210 to 0.70432, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-25-0.70.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.4465 - recall: 0.7727 - val_loss: 0.5784 - val_recall: 0.7043\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4351 - recall: 0.7829\n",
      "Epoch 26: val_recall improved from 0.70432 to 0.72868, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-26-0.73.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.4351 - recall: 0.7829 - val_loss: 0.6161 - val_recall: 0.7287\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4189 - recall: 0.7899\n",
      "Epoch 27: val_recall did not improve from 0.72868\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.4189 - recall: 0.7899 - val_loss: 0.6065 - val_recall: 0.7154\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4332 - recall: 0.7896\n",
      "Epoch 28: val_recall did not improve from 0.72868\n",
      "113/113 [==============================] - 15s 129ms/step - loss: 0.4332 - recall: 0.7896 - val_loss: 0.6193 - val_recall: 0.6844\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4166 - recall: 0.7935\n",
      "Epoch 29: val_recall did not improve from 0.72868\n",
      "113/113 [==============================] - 15s 130ms/step - loss: 0.4166 - recall: 0.7935 - val_loss: 0.5911 - val_recall: 0.7099\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4141 - recall: 0.7899\n",
      "Epoch 30: val_recall did not improve from 0.72868\n",
      "113/113 [==============================] - 15s 129ms/step - loss: 0.4141 - recall: 0.7899 - val_loss: 0.7016 - val_recall: 0.6877\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3839 - recall: 0.8178\n",
      "Epoch 31: val_recall did not improve from 0.72868\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3839 - recall: 0.8178 - val_loss: 0.6549 - val_recall: 0.7099\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.4122 - recall: 0.7982\n",
      "Epoch 32: val_recall did not improve from 0.72868\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.4122 - recall: 0.7982 - val_loss: 0.6791 - val_recall: 0.6766\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3679 - recall: 0.8261\n",
      "Epoch 33: val_recall did not improve from 0.72868\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3679 - recall: 0.8261 - val_loss: 0.6829 - val_recall: 0.7032\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3576 - recall: 0.8264\n",
      "Epoch 34: val_recall improved from 0.72868 to 0.72979, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-34-0.73.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3576 - recall: 0.8264 - val_loss: 0.7028 - val_recall: 0.7298\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3703 - recall: 0.8272\n",
      "Epoch 35: val_recall did not improve from 0.72979\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3703 - recall: 0.8272 - val_loss: 0.6609 - val_recall: 0.7076\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3580 - recall: 0.8339\n",
      "Epoch 36: val_recall improved from 0.72979 to 0.73754, saving model to C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Undersampling Training 4515 (NV 6705-5500=1205)\\weights-improvement-36-0.74.hdf5\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3580 - recall: 0.8339 - val_loss: 0.6223 - val_recall: 0.7375\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3394 - recall: 0.8408\n",
      "Epoch 37: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3394 - recall: 0.8408 - val_loss: 0.7077 - val_recall: 0.7021\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3252 - recall: 0.8486\n",
      "Epoch 38: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3252 - recall: 0.8486 - val_loss: 0.7038 - val_recall: 0.7021\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3156 - recall: 0.8524\n",
      "Epoch 39: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3156 - recall: 0.8524 - val_loss: 0.7650 - val_recall: 0.6955\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3120 - recall: 0.8488\n",
      "Epoch 40: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3120 - recall: 0.8488 - val_loss: 0.7186 - val_recall: 0.7209\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2989 - recall: 0.8616\n",
      "Epoch 41: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.2989 - recall: 0.8616 - val_loss: 0.7749 - val_recall: 0.7209\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3054 - recall: 0.8602\n",
      "Epoch 42: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3054 - recall: 0.8602 - val_loss: 0.7470 - val_recall: 0.7254\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2878 - recall: 0.8624\n",
      "Epoch 43: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.2878 - recall: 0.8624 - val_loss: 0.9242 - val_recall: 0.7309\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2906 - recall: 0.8674\n",
      "Epoch 44: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.2906 - recall: 0.8674 - val_loss: 0.9374 - val_recall: 0.6966\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.3077 - recall: 0.8674\n",
      "Epoch 45: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.3077 - recall: 0.8674 - val_loss: 0.9486 - val_recall: 0.7110\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - ETA: 0s - loss: 0.2620 - recall: 0.8857\n",
      "Epoch 46: val_recall did not improve from 0.73754\n",
      "113/113 [==============================] - 14s 128ms/step - loss: 0.2620 - recall: 0.8857 - val_loss: 0.9683 - val_recall: 0.7065\n",
      "Epoch 46: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2da5d2732e0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['Recall'],\n",
    "              )\n",
    "\n",
    "model.fit(X, y_one_hot,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd4aa4",
   "metadata": {},
   "source": [
    "# Load Model Built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5470843",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Z6\\Desktop\\Skripsi 10120060 (Jangan Sentuh)\\Model\\Pembagian Berdasarkan Kanker atau Tidak\\Resnet50. Size 224, Batch 32, FC 1000, Iter 125, val 0.2\\\\'\n",
    "model_path = path + \"weights-improvement-10-0.85\" + \".hdf5\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0274a",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603e578f",
   "metadata": {},
   "source": [
    "## Predict From Existed and Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = X_Test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266047c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=X_Test, steps=len(X_Test), verbose=1)\n",
    "print(\"\")\n",
    "print(predictions)\n",
    "print(\"\")\n",
    "print(f'Prediction shape: {predictions.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix Berdasarkan Penyakit\n",
    "cm = confusion_matrix(y_true=y_Test, y_pred=np.argmax(predictions, axis=-1))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "    print(\"\")\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "cm_plot_labels = [\"Kanker\", \"Non-Kanker\"]\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(confusion_matrix):\n",
    "    correct_predictions = np.sum(np.diag(confusion_matrix))\n",
    "    total_predictions = np.sum(confusion_matrix)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Assuming 'cm' is the confusion matrix obtained\n",
    "accuracy = calculate_accuracy(cm)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35e32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming 'cm' is the confusion matrix obtained\n",
    "class_names = [\"Kanker\", \"Non-Kanker\"]\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "classification_rep = classification_report(y_true=y_Test, y_pred=np.argmax(predictions, axis=-1),\n",
    "                                           target_names=class_names)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "#Precision = TP/(TP + FP)\n",
    "#Recall = TP/(TP +  FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27346566",
   "metadata": {},
   "source": [
    "## Predict Input From User  (Belum Beres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6478e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harusnya bukan begini karena ini bukan colab\n",
    "input_predict = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb795cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Kanker\", \"Non-Kanker\"]\n",
    "def prepare(content):\n",
    "    img_array = cv2.imdecode(np.frombuffer(content, np.uint8), cv2.IMREAD_COLOR)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    new_array = new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    normalized_data = new_array / 255.0\n",
    "    return normalized_data\n",
    "\n",
    "file_content = next(iter(input_predict.values()))\n",
    "prediction = model.predict([prepare(file_content)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Kategori yang ada = {CATEGORIES}')\n",
    "print(f'Peluang Kelas = {prediction}')\n",
    "print(\"\")\n",
    "\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "#akiec, bcc, mel\n",
    "if predicted_class == 0 or predicted_class == 1 or predicted_class == 4:\n",
    "  kanker = \"kanker\"\n",
    "  print(f'Prediksi dari gambar berkelas {CATEGORIES[predicted_class]}, {kanker}.')\n",
    "#bkl, df, nv, vasc\n",
    "else:\n",
    "  kanker = \"non-kanker\"\n",
    "  print(f'Prediksi dari gambar adalah {CATEGORIES[predicted_class]}, {kanker}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
